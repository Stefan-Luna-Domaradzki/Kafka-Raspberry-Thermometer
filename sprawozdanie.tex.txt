%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% %
%%% % weiiszablon.tex
%%% % The Faculty of Electrical and Computer Engineering
%%% % Rzeszow University Of Technology diploma thesis Template
%%% % Szablon pracy dyplomowej Wydziału Elektrotechniki 
%%% % i Informatyki PRz
%%% % June, 2015
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[12pt,twoside]{article}

\usepackage{weiiszablon}

\author{Stefan Domaradzki}

% np. EF-123456, EN-654321, ...
\studentID{FS-166642}

\title{Agregacja danych z czujnika i Raspberry Pi przy użyciu Apache Kafka i języka Python}
\titleEN{Temat pracy po angielsku}


%%% wybierz rodzaj pracy wpisując jeden z poniższych numerów: ...
% 1 = inżynierska	% BSc
% 2 = magisterska	% MSc
% 3 = doktorska		% PhD
%%% na miejsce zera w linijce poniżej
\newcommand{\rodzajPracyNo}{4}


%%% promotor
\supervisor{Dr. Marek Bolanowski}
%% przykład: dr hab. inż. Józef Nowak, prof. PRz


\begin{document}

% strona tytułowa
\maketitle

\blankpage

% spis treści
\tableofcontents

\newpage
\section{Data streaming}
Strumieniowanie danych (data streaming) jest procesem przetwarzania danych, który polega na przesyłaniu ich strumieniowo, tzn. w czasie rzeczywistym lub w małych paczkach, zamiast jednorazowo przesłać cały zbiór danych. Strumienie danych pochodzą z różnych źródeł, takich jak sensory lub aplikacje internetowe. Strumieniowanie danych pozwala na przetwarzanie i analizowanie danych w czasie rzeczywistym, co umożliwia szybkie reagowanie na zmieniające się warunki.



\section{Raspberry Pi}
Raspberry Pi to mały jednopłytkowy komputer o stosunkowowo dobrej mocy obliczeniowej. Na jednej małej płytce znajdują się procesor, pamięć RAM, USB, HDMI, czy Ethernet. Architektura płytki została oparta na układzie systemu na chipie (SoC). I jest w stanie uruchamiać standardowe systemy operacyjne, lub dedytkowany Raspberry Pi OS.


\section{Realizacja}

\subsection{Konfiguracja RaspberryPi}
\subsubsection{System Operacyjny}
Instalacja systemu operacyjnego na RaspberryPi jest bardzo prosta. Wykorzystane zostaje darmowe oprogramowanie zapewnione przez producenta mikrokomputera o nazwie \textit{Raspberry Pi Imager"}. Dzięki niemu mamy dostęp wybrania preferowanego systemu operacyjnego. Wybrano \textit{RaspberryPi OS (32-bit)}. Wybieramy docelowe miejsce instalacji systemu (Karta microSD).

\subsubsection{Konfiguracja IP}
Dla prostszego łączenia się z Raspberry skonfigurowano statyczny adres IP dla połączenia przewodowego. Ponieważ nie istnieje możliwość ustawienia tego parametru z poziomu instalatora \textit{Raspberry Pi Imager}, należy dokonać edycji pliku znajdującego się pod następującą ścieżką \textit{\etc\dhcpcd.conf} zgodnie z zamieszczonym rysunkiem.

\\
\begin{figure}[htb]
    \centering
    \includegraphics[width=12cm]{interface eth0.png}
    \caption{Konfiguracja pliku dhcpcd.conf}
    \label{fig:dhcpcd.conf}
\end{figure}
\\

Oczywiście nadany adres może być dowolny należy jednak pamiętać, że to za jego pomocą następuje połączenie do urządzenie.

W przypadku wiersza \textit{staticrouters} zapisujemy IP urządzenia które służy jako router i jednocześnie Kafka Server.

\\
\begin{figure}[htb]
    \centering
    \includegraphics[width=8cm]{eth0 PC.png}
    \caption{Konfiguracja sieci na PC}
    \label{fig:dhcpcd.conf}
\end{figure}
\\

\subsubsection{DNS resolution }

Jeśli nie jest możliwe przypisanie nazwy hosta do adresu IP, nastąpi błąd w wyszukiwaniu DNS.

Jeśli DNS resolution nie działa poprawnie, należy dodać wpis do pliku \textit{/etc/hosts} na Raspberry Pi. Po otworzeniu  za pomocą dowolnego edytora tekstu należy dodać w nim linijkę z adresem IP brokera Kafka i jego nazwą hosta. Przykładowo:
\\
\begin{center}

\textit{192.168.1.218  "Nazwa Hosta"}

\end{center}
\\

Dobrą praktyką jest również wyczyszczenie pamięci podręcznej i resolverów na maszynie funkcjonującej jako Kafka server Co zagwarantuje aktualność wszystkich rekordów DNS.

\\
\begin{figure}[htb]
    \centering
    \includegraphics[width=8cm]{flush dns.png}
    \caption{Czyszczenie pamięci podręcznej DNS}
    \label{fig:flushdns}
\end{figure}
\\


\subsection{Połączenie}
Połączenie następuje poprzez użycie SSH. SSH to standard protokołów komunikacyjnych używanych w sieciach komputerowych TCP/IP. 
Po podłączeniu Raspberry Pi za pomocą przewodu sieciowego do urządzenia działającego jako serwer Kafki wykonujemy następującą komendę:

\\
\begin{center}
    \textit{SSH pi@192.168.1.217}
\end{center}
\\

Pamiętając, że jest to wcześniej ustawiony adres używanego mikrokomputera.

Sprawdzenie dostępności portu na którym pracuje \textit{Kafka Server}:
\newpage
\\
\begin{figure}[htb]
    \centering
    \includegraphics[width=12cm]{port connection test.png}
    \caption{Test dostępności portu 9092}
    \label{fig:9092 connection}
\end{figure}
\\


\subsection{Termometr}

Wykorzystano następujący schemat połączenia czujnika \textit{DS18B20}  z Raspberry Pi:

\\
\begin{figure}[htb]
    \centering
    \includegraphics[width=12cm]{schemat połączenia.png}
    \caption{Termometr schemat połączenia}
    \label{fig:Termometr schemat połączenia}
\end{figure}
\\
Aby jednak można było odczytać temperaturę z czujnika należy włączyć odpowiedni sterownik w jądrze systemu Raspberry.

Aby to zrobić należy włączyć panel konfiguracji:

\\
\begin{center}
    \textit{sudo raspi-config}
\end{center}
\\
I w zakładce "Interfacing Options" włączyć opcję: P7 1-Wire.
Na koniec należy zrestartować użądzenie za pomocą komendy: 
\\
\begin{center}
    \textit{sudo reboot now}
\end{center}
\\

\subsection{Skrypty w języku python}

\subsubsection{Temperature Producer}

Skrypt \textit{Temperature Producer} znajduje się na wykorzystywanym urządzeniu Raspberry Pi. Korzysta on z dwóch bibliotek

\begin{itemize}
    \item w1thermsensor - zawiera metodę do pobrania temeratury z czujnika,
    \item kafka - odpowiada za przysyłanie wiadomości do servera kafki
\end{itemize}



Na początku należy dokonać definicji producenta wiadomości dla serwera Kafka, przypisujemy adres hosta i port hosta, oraz wybieramy sposób serializowania wiadomości, może być dowolny, lecz należy pamiętać by był on zgodny ze sposobem użytym w konsumerze.

\begin{lstlisting}[language=Python,caption=Definicja producera Kafka,label={Producer Kaf}]
temperature_producer = KafkaProducer(
    bootstrap_server=['host_ip:port'], #change to current host IP
    value_serializer=lamba v: json.dumps(v).encode('utf-8'),
    api_version=(3,3,1)
    )

\end{lstlisting}
\\
Protokołem wykorzystywanym jest domyślny dla Kafki protokół TCP.

Pętla \textit{While} odpowiadająca za pobranie i wysłanie informacji. Operacja wysyłania zostaje zakończona komendą \textit{producer.flush()}. Gwarantującą, że wszystkie wiadomości przygotowane do wysłania trafią do brokera wiadomości kafka.
\\ 
\begin{lstlisting}[language=Python,caption=Definicja producera Kafka,label={Producer Kaf}]
kafka_topic = 'Ethernet'
    
    while True:

        temperature = sensor.get_temperature()
        temperature_producer.send(kafka_topic, temperature)
        temperature_producer.flush()
        sleep(1)
\end{lstlisting}

\subsection{Consumer.py}
Kafka Consumer znajduje się na tej samej maszynie która służy za \textit{Kafka Server}. Z tego powodu w skrypcie wykorzystano argument: \begin{textit} bootstrap\_servers[localhost:9092] \end{textit} 

Kafka Consumer definiujemy analogicznie do Producera:

\begin{lstlisting}[language=Python,caption=Definicja producera Kafka,label={Producer Kaf}]
simple_consumer = KafkaConsumer(
                    auto_offset_reset='earliest',
                    bootstrap_servers=['localhost:9092'],
                    api_version=(3,3,1))

simple_consumer.subscribe('Ethernet')                    
\end{lstlisting}
Operacja kończy się zasubskrybowaniem do tematu z którego docelowo będą zczytywane dane.
Parametr \textit{earliest} jest kluczowy, gdyż dzięki niemu możliwe jest odczytywanie wiadomości w miarę jak nadchodzą, co jest funkjcjonalnością ostatniej części \textit{Consumera}. 




\section{Wnioski}
Projekt z wykorzystaniem czujnika temperatury, Raspberry Pi i biblioteki Kafka Python dostarczył wartościowych wniosków oraz zapewnił cenne doświadczenie związane z sieciami komputerowymi. Debugowanie błędów połączenia z brokerem Kafka ujawniło problem z DNS Resolution. Rozwiązanie wymagało edycji pliku \textit{/etc/hosts}. rojekt dostarczył cenne doświadczenie w zakresie konfiguracji połączenia z brokerem Kafka, produkcji i konsumpcji danych w czasie rzeczywistym oraz rozwiązywania problemów z sieciami komputerowymi.

\section{Pliki projektu}
https://github.com/Stefan-Luna-Domaradzki/Kafka-Raspberry-Thermometer

\addcontentsline{toc}{section}{Literatura}

\begin{thebibliography}{4}
\bibitem{str} http://weii.portal.prz.edu.pl/pl/materialy-do-pobrania. Dostęp 5.01.2015.
\bibitem{str} https://forbot.pl/blog/kurs-raspberry-pi-czujnik-temperatury-ds18b20-id26430
\end{thebibliography}

\clearpage

\makesummary

\end{document} 
